# Example environment variables for SMOLTRACE
# Copy this file to .env and fill in your values

# ============================================================================
# REQUIRED: HuggingFace Token
# ============================================================================
# HuggingFace token with write access to push datasets
# Get yours from: https://huggingface.co/settings/tokens
# Required for all SMOLTRACE operations (dataset creation, leaderboard updates)
HF_TOKEN=hf_YOUR_HUGGINGFACE_TOKEN_HERE

# ============================================================================
# API PROVIDER KEYS (choose based on your model provider)
# ============================================================================
# At least ONE API key required when using --provider=litellm
# SMOLTRACE checks for these keys in the order listed below

# OpenAI (for GPT-3.5, GPT-4, GPT-4o models)
# Get from: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-YOUR_OPENAI_API_KEY

# Anthropic (for Claude 3 models)
# Get from: https://console.anthropic.com/settings/keys
ANTHROPIC_API_KEY=sk-ant-YOUR_ANTHROPIC_API_KEY

# Mistral AI (for Mistral models)
# Get from: https://console.mistral.ai/api-keys/
MISTRAL_API_KEY=YOUR_MISTRAL_API_KEY

# Groq (for fast inference of Llama, Mixtral models)
# Get from: https://console.groq.com/keys
GROQ_API_KEY=gsk_YOUR_GROQ_API_KEY

# Together AI (for various open-source models)
# Get from: https://api.together.xyz/settings/api-keys
TOGETHER_API_KEY=YOUR_TOGETHER_API_KEY

# Generic LiteLLM API key (for custom providers)
LITELLM_API_KEY=YOUR_LITELLM_API_KEY

# ============================================================================
# OPTIONAL: Local Model Providers (No API key needed)
# ============================================================================

# Ollama: Local models via Ollama server
# Ensure Ollama is running at: http://localhost:11434
# Install from: https://ollama.ai
# No environment variables needed - just start the Ollama server

# Transformers: HuggingFace GPU models
# Requires: GPU/CUDA on your system
# No API key needed - uses local models from HuggingFace Hub
# Models are cached in: ~/.cache/huggingface/hub/

# Inference: HuggingFace Inference API (InferenceClientModel)
# Uses HF_TOKEN for authentication (no separate API key needed)
# Access to hosted models without local GPU requirements

# ============================================================================
# OPTIONAL: Search Tool API Keys (for --enable-tools google_search)
# ============================================================================

# Serper API (professional search API)
# Get from: https://serper.dev/
# Used with: --enable-tools google_search --search-provider serper
SERPER_API_KEY=YOUR_SERPER_API_KEY

# Brave Search API
# Get from: https://brave.com/search/api/
# Used with: --enable-tools google_search --search-provider brave
BRAVE_API_KEY=YOUR_BRAVE_API_KEY

# Note: DuckDuckGo search provider doesn't require an API key

# ============================================================================
# OPTIONAL: Model-Specific Configuration
# ============================================================================

# For private HuggingFace model access (gated models)
# Same as HF_TOKEN above - no separate token needed

# Custom base URLs for API providers (advanced)
# OPENAI_API_BASE=https://api.openai.com/v1
# ANTHROPIC_API_BASE=https://api.anthropic.com
# MISTRAL_API_BASE=https://api.mistral.ai

# ============================================================================
# SMOLTRACE Configuration (Optional)
# ============================================================================

# Default output format (hub or json)
# SMOLTRACE_OUTPUT_FORMAT=hub

# Default output directory for local JSON files
# SMOLTRACE_OUTPUT_DIR=./smoltrace_results

# Enable debug logging
# SMOLTRACE_DEBUG=false
